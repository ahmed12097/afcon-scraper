import os
import re
import time
import random
import pandas as pd
from bs4 import BeautifulSoup
from io import StringIO
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ®ÙÙŠ ÙˆØªØ«Ø¨ÙŠØªÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù†Ù‚ØµØª
try:
    from selenium_stealth import stealth
except ImportError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "selenium-stealth"])
    from selenium_stealth import stealth

# =========================
# âœ… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªØµÙØ­ Ø§Ù„Ù…Ø®ÙÙŠ (Ù„Ù„Ø¨ÙˆØ± Ø¨ÙŠ Ø¢ÙŠ ÙˆØ¬ÙŠØª Ù‡Ø¨)
# =========================
def get_stealth_driver():
    options = Options()
    options.add_argument("--headless=new") # ØªØ´ØºÙŠÙ„ Ø®ÙÙŠ Ù„Ø¹Ø¯Ù… ØªØ¹Ø·ÙŠÙ„ Power BI
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    
    # Ø¥Ø®ÙØ§Ø¡ Ù‡ÙˆÙŠØ© Ø§Ù„Ø£ØªÙ…ØªØ©
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    # Ø¥Ø¶Ø§ÙØ© User-Agent Ø­Ù‚ÙŠÙ‚ÙŠ
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # âœ… ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ© Stealth Ù„Ø¥Ø®ÙØ§Ø¡ Ø¨ØµÙ…Ø© Selenium ØªÙ…Ø§Ù…Ø§Ù‹
    stealth(driver,
            languages=["en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True)
    return driver

# =========================
# âœ… Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (Cleaning)
# =========================
def clean_team_name(name):
    name = str(name).strip()
    name = re.sub(r"^[a-z]{2}\s+", "", name)
    name = re.sub(r"\s+[a-z]{2}$", "", name)
    return name.strip()

def get_match_report_links(html):
    soup = BeautifulSoup(html, "html.parser")
    match_links = []
    rows = soup.select("table.stats_table tbody tr")
    for r in rows:
        report_cell = r.find("td", {"data-stat": "match_report"})
        if report_cell and report_cell.find("a"):
            link = "https://fbref.com" + report_cell.find("a")["href"]
            match_links.append(link)
    return match_links

# =========================
# âœ… Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Main Logic)
# =========================
SCHEDULE_URL = "https://fbref.com/en/comps/656/schedule/"
driver = get_stealth_driver()

try:
    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙˆÙ‚Ø¹...")
    driver.get(SCHEDULE_URL)
    
    # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ Ù„Ø¸Ù‡ÙˆØ± Ø§Ù„Ø¬Ø¯ÙˆÙ„
    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.stats_table")))
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ø­Ø±ÙƒØ© Ø¨Ø´Ø±ÙŠØ© Ø¨Ø³ÙŠØ·Ø© (ØªØµÙØ­)
    driver.execute_script("window.scrollBy(0, 500);")
    time.sleep(random.uniform(2, 4))
    
    html_main = driver.page_source
    print("âœ… ØªÙ… Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
finally:
    driver.quit()

# ØªØ­ÙˆÙŠÙ„ HTML Ø¥Ù„Ù‰ DataFrame
tables = pd.read_html(StringIO(html_main))
raw_df = tables[0].copy()

# âœ… 1. Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª (afcon_2025_matches)
raw_df = raw_df.dropna(subset=["Date", "Home", "Away"]).copy()
raw_df["HomeTeam"] = raw_df["Home"].apply(clean_team_name)
raw_df["AwayTeam"] = raw_df["Away"].apply(clean_team_name)
raw_df["Date"] = pd.to_datetime(raw_df["Date"], errors="coerce")

# ÙØµÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
raw_df["Score"] = raw_df["Score"].astype(str)
score_split = raw_df["Score"].str.split("â€“", expand=True)
if score_split.shape[1] >= 2:
    raw_df["HomeGoals"] = pd.to_numeric(score_split[0], errors="coerce")
    raw_df["AwayGoals"] = pd.to_numeric(score_split[1], errors="coerce")
else:
    raw_df["HomeGoals"], raw_df["AwayGoals"] = None, None

raw_df["MatchStatus"] = raw_df["HomeGoals"].apply(lambda x: "Played" if pd.notna(x) else "Upcoming")
raw_df["MatchID"] = raw_df["Date"].astype(str).str[:10] + "_" + raw_df["HomeTeam"].str.replace(" ", "")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
match_links = get_match_report_links(html_main)
raw_df["MatchReportLink"] = None
played_idx = raw_df[raw_df["MatchStatus"] == "Played"].index.tolist()
for idx, link in zip(played_idx, match_links):
    raw_df.loc[idx, "MatchReportLink"] = link

# Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªØ¸Ù‡Ø± ÙÙŠ Power BI Navigator:
afcon_2025_matches = raw_df[["MatchID", "Date", "Time", "MatchStatus", "HomeTeam", "AwayTeam", "HomeGoals", "AwayGoals", "Score", "Venue", "Referee", "MatchReportLink"]].copy()

# âœ… 2. ØªÙ„Ø®ÙŠØµ Ø§Ù„ÙØ±Ù‚ (teams_summary)
teams_summary = (afcon_2025_matches.groupby("HomeTeam").agg(PlayedMatches=("MatchID", "count")).reset_index())

# Ù…Ù„Ø§Ø­Ø¸Ø© Ù„Ù€ Power BI: Ø³ÙŠØ¸Ù‡Ø± Ù„Ùƒ Ø¬Ø¯Ø§ÙˆÙ„ afcon_2025_matches Ùˆ teams_summary ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.
