import os
import re
import time
import random
import pandas as pd
from bs4 import BeautifulSoup
from io import StringIO
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# âœ… ØªØ«Ø¨ÙŠØª ÙˆØªÙØ¹ÙŠÙ„ Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ®ÙÙŠ Ù„ØªØ¬Ø§ÙˆØ² Ø§Ù„ÙƒØ§Ø¨ØªØ´Ø§
try:
    from selenium_stealth import stealth
except ImportError:
    import subprocess
    import sys
    subprocess.check_call([sys.executable, "-m", "pip", "install", "selenium-stealth"])
    from selenium_stealth import stealth

# =========================
# âœ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ Ø¨Ø£Ù‚ØµÙ‰ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„ØªØ®ÙÙŠ
# =========================
def get_advanced_stealth_driver():
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    
    # Ø¥Ø®ÙØ§Ø¡ Ù‡ÙˆÙŠØ© Ø§Ù„Ø£ØªÙ…ØªØ© ØªÙ…Ø§Ù…Ø§Ù‹
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    # Ù…Ø­Ø§ÙƒØ§Ø© Ù…ØªØµÙØ­ Ø­Ù‚ÙŠÙ‚ÙŠ
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # ØªØ·Ø¨ÙŠÙ‚ Stealth Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø´Ø±ÙŠØ© (Ù„ØºØ§ØªØŒ ÙƒØ±Øª Ø§Ù„Ø´Ø§Ø´Ø©ØŒ Ø§Ù„Ù…Ù†ØµØ©)
    stealth(driver,
            languages=["en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True)
    return driver

# =========================
# âœ… Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ
# =========================
def clean_team_name(name):
    name = str(name).strip()
    name = re.sub(r"^[a-z]{2}\s+", "", name)
    name = re.sub(r"\s+[a-z]{2}$", "", name)
    return name.strip()

def get_match_report_links(html):
    soup = BeautifulSoup(html, "html.parser")
    match_links = []
    rows = soup.select("table.stats_table tbody tr")
    for r in rows:
        report_cell = r.find("td", {"data-stat": "match_report"})
        if report_cell and report_cell.find("a"):
            link = "https://fbref.com" + report_cell.find("a")["href"]
            match_links.append(link)
    return match_links

# =========================
# âœ… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# =========================
URL = "https://fbref.com/en/comps/656/schedule/"
driver = get_advanced_stealth_driver()

try:
    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…ÙˆÙ‚Ø¹...")
    driver.get(URL)
    
    # Ø§Ù†ØªØ¸Ø§Ø± Ø°ÙƒÙŠ Ù„Ø¸Ù‡ÙˆØ± Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯
    WebDriverWait(driver, 40).until(EC.presence_of_element_located((By.CSS_SELECTOR, "table.stats_table")))
    
    # Ù…Ø­Ø§ÙƒØ§Ø© ØªØµÙØ­ Ø¨Ø´Ø±ÙŠ Ø¨Ø§Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ
    driver.execute_script("window.scrollBy(0, 400);")
    time.sleep(random.uniform(3, 6))
    
    html_content = driver.page_source
    print("âœ… ØªÙ… Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
finally:
    driver.quit()

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø¯Ø§ÙˆÙ„
tables = pd.read_html(StringIO(html_content))
matches_raw = tables[0].copy()

# âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
matches_raw = matches_raw.dropna(subset=["Date", "Home", "Away"]).copy()
matches_raw["HomeTeam"] = matches_raw["Home"].apply(clean_team_name)
matches_raw["AwayTeam"] = matches_raw["Away"].apply(clean_team_name)
matches_raw["Date"] = pd.to_datetime(matches_raw["Date"], errors="coerce")

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù
matches_raw["Score"] = matches_raw["Score"].astype(str)
score_parts = matches_raw["Score"].str.split("â€“", expand=True)
if score_parts.shape[1] >= 2:
    matches_raw["HomeGoals"] = pd.to_numeric(score_parts[0], errors="coerce")
    matches_raw["AwayGoals"] = pd.to_numeric(score_parts[1], errors="coerce")
else:
    matches_raw["HomeGoals"], matches_raw["AwayGoals"] = None, None

matches_raw["MatchStatus"] = matches_raw["HomeGoals"].apply(lambda x: "Played" if pd.notna(x) else "Upcoming")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø§Ù„Ù…Ù„Ø¹ÙˆØ¨Ø©
links = get_match_report_links(html_content)
matches_raw["MatchReportLink"] = None
played_rows = matches_raw[matches_raw["MatchStatus"] == "Played"].index.tolist()
for i, l in zip(played_rows, links):
    matches_raw.loc[i, "MatchReportLink"] = l

# Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ Ø³ØªØ¸Ù‡Ø± ÙÙŠ Power BI
afcon_2025_matches = matches_raw[["Date", "Time", "MatchStatus", "HomeTeam", "AwayTeam", "HomeGoals", "AwayGoals", "Score", "Venue", "Referee", "MatchReportLink"]].copy()

teams_summary = afcon_2025_matches.groupby("HomeTeam").size().reset_index(name="MatchesCount")

# âœ… Ø£Ù…Ø± Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ù„Ø¬ÙŠØª Ù‡Ø¨ ÙˆÙ„Ù„Ø¬Ù‡Ø§Ø²)
OUTPUT_DIR = "data"
os.makedirs(OUTPUT_DIR, exist_ok=True)
afcon_2025_matches.to_csv(os.path.join(OUTPUT_DIR, "afcon_2025_matches.csv"), index=False, encoding="utf-8-sig")
