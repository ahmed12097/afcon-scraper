name: Update AFCON Data (Selenium)

on:
  schedule:
    - cron: "0 */6 * * *"   # كل 6 ساعات
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # ✅ Install Google Chrome (stable)
      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install dependencies
        run: pip install -r requirements.txt

      # ✅ Run scraper
      - name: Run scraper
        run: python scrape.py

      # ✅ Upload debug HTML if scraper failed (won't fail if missing)
      - name: Upload debug HTML (if exists)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-page
          path: debug_page.html
          if-no-files-found: warn

      # ✅ Commit & Push CSV outputs (only if scraper succeeded)
      - name: Commit & Push updated CSVs
        if: success()
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add data/*.csv
          git commit -m "Auto update AFCON data" || echo "No changes"
          git push
